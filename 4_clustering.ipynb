{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model_fit import do_StepMix, do_kmeans, do_AHC, do_hdbscan\n",
    "from src.model_select import bootstrap_gap, compute_gap, get_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148a1b3-b53c-4704-8a8c-a3adaace68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9a92e-c873-4ec3-b75d-a7fe171a7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVI = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "max_threads = 8\n",
    "\n",
    "approach = 'replic_830' # replic_830 / replic_1077 / own_1215\n",
    "\n",
    "max_clust = 16\n",
    "gap_iters = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7295e-5ad2-4eba-9154-76b74d4732c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = ['clseusa']\n",
    "q3 = ['ambornin', 'amcit', 'amlived', 'amenglsh', \n",
    "      'amchrstn', 'amgovt', 'amfeel']\n",
    "q4 = ['amcitizn', 'amshamed', 'belikeus', 'ambetter', 'ifwrong']\n",
    "q5 = ['proudsss', 'proudgrp', 'proudpol', 'prouddem', 'proudeco',\n",
    "      'proudspt','proudart', 'proudhis', 'proudmil', 'proudsci']\n",
    "\n",
    "# if 'own' in approach:\n",
    "#    q2 = q2 + ['clsetown', 'clsestat', 'clsenoam']\n",
    "#    q3 = q3 + ['amancstr']\n",
    "#    q4 = q4 + ['amsports', 'lessprd']\n",
    "\n",
    "q2_n = [var + \"_n\" for var in q2]\n",
    "q3_n = [var + \"_n\" for var in q3]\n",
    "q4_n = [var + \"_n\" for var in q4]\n",
    "q5_n = [var + \"_n\" for var in q5]\n",
    "\n",
    "var_list = q2 + q3 + q4 + q5\n",
    "var_list_f = [var + \"_f\" for var in var_list]\n",
    "var_list_n = [var + \"_n\" for var in var_list]\n",
    "\n",
    "ctrl_list = ['party_f', 'race_f', 'educ_f', 'region_f', 'reltrad_f', \n",
    "             'religstr_f', 'born_usa_f', 'sex_f', 'age_n', \n",
    "             'lnrealinc2004_n', 'age_n', 'lnrealinc2004_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e767a2f-4830-453c-a044-bcd771b288ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '830' in approach:\n",
    "    data2004 = pd.read_parquet(f\"data/data2004_830.parquet\")\n",
    "elif '1077' in approach:\n",
    "    data2004 = pd.read_parquet(f\"data/data2004_1077.parquet\")\n",
    "else:\n",
    "    data2004 = pd.read_parquet(f\"data/data2004_1215.parquet\")\n",
    "\n",
    "# Dataset with numeric outcomes\n",
    "scaler = StandardScaler()\n",
    "data_n = data2004[var_list_n]\n",
    "data_n = pd.DataFrame(scaler.fit_transform(data_n), columns=data_n.columns, index=data_n.index)\n",
    "\n",
    "# Dataset with categorical outcomes and reindexing to 0 (as expected by StepMix)\n",
    "data_f = data2004[var_list_n] - 1\n",
    "\n",
    "# Dataset with controls (same as the authors)\n",
    "controls = data2004[ctrl_list]\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "\n",
    "# Sample weights\n",
    "weights = data2004['wgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231f205-f001-446c-a3f4-0b3bc4e1a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate: dataframe with weighted numeric outcomes\n",
    "# Weighting after scaling (otherwise it defeats the purpose...)\n",
    "\n",
    "data_n_w = pd.DataFrame()\n",
    "\n",
    "q2_wgt = len(q2) / len(var_list)\n",
    "q3_wgt = len(q3) / len(var_list)\n",
    "q4_wgt = len(q4) / len(var_list)\n",
    "q5_wgt = len(q5) / len(var_list)\n",
    "\n",
    "for var in q2_n:\n",
    "    data_n_w.loc[:, var] = data_n[var] * q2_wgt\n",
    "\n",
    "for var in q3_n:\n",
    "    data_n_w.loc[:, var] = data_n[var] * q3_wgt\n",
    "\n",
    "for var in q4_n:\n",
    "    data_n_w.loc[:, var] = data_n[var] * q4_wgt\n",
    "\n",
    "for var in q5_n:\n",
    "    data_n_w.loc[:, var] = data_n[var] * q5_wgt\n",
    "\n",
    "# Remove the _w suffix to inject into main code\n",
    "data_n_w = pd.DataFrame(data_n_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513b5bc-963b-41e5-a6bd-12f45f22c2f5",
   "metadata": {},
   "source": [
    "# 1. Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63d684-cd9c-43f6-9e4d-f457752063f6",
   "metadata": {},
   "source": [
    "## 1.1. Latent\n",
    "\n",
    "Only base models as NAs, covariates, and sample weights are not compatible with the gap procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2c93b-6c33-4b31-855f-2b5a1d37a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msrt = ['categorical', 'continuous']\n",
    "msrt = ['categorical']\n",
    "covar = ['without']\n",
    "latent_params = list(product(msrt, covar))\n",
    "clust_range = range(1, max_clust+1)\n",
    "latent_grid = product(clust_range, latent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a46013-27ca-46c9-bc6a-f9b44aa2f9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs = max_threads)(\n",
    "    delayed(do_StepMix)(\n",
    "        data_f if 'categorical' in msrt else data_n,\n",
    "        controls_dum if covar == 'with' else None,\n",
    "        n,\n",
    "        msrt,\n",
    "        covar)\n",
    "    for n, (msrt, covar) in tqdm(latent_grid, desc='Fitting latent models'))\n",
    "\n",
    "latent_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352bf1e-cfde-42a2-8f19-0b5a0f6e4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert params to legacy format (without infos on NAs and weights)\n",
    "latent_all['params'] = latent_all['params'].apply(\n",
    "    lambda d: {k: v for k, v in d.items() if k not in ['NAs', 'wgt']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa257eee-187a-4c71-9f45-6001cce0b478",
   "metadata": {},
   "source": [
    "## 1.2. k-means\n",
    "\n",
    "With a custom implementation, as scikit-learn does not allow to change the linkage function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87945e4f-7069-4a5e-8ec1-b0ef4cb07994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = ['euclidean', 'manhattan', 'chebyshev']\n",
    "link = ['mean', 'median', 'medoid']\n",
    "kmeans_params = list(product(dist, link))\n",
    "\n",
    "clust_range = range(2, max_clust+1)\n",
    "kmeans_grid = product(clust_range, kmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa878a3-e45f-4205-89dd-279a0c921f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_kmeans)(data_n, n, dist, link) \n",
    "    for n, (dist, link) in tqdm(kmeans_grid, desc='Fitting KMeans models'))\n",
    "\n",
    "kmeans_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a232344-8695-4408-8564-f72d79b7ecd2",
   "metadata": {},
   "source": [
    "## 1.3. AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ab7f5-cafd-49ac-84da-e97c878c05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ['manhattan', 'euclidean', 'chebyshev', 'hamming']\n",
    "linkages = ['single', 'average', 'complete']\n",
    "ahc_params = [*product(distances, linkages), ('euclidean', 'ward')]\n",
    "\n",
    "clust_range = range(1, max_clust+1)\n",
    "ahc_grid = product(clust_range, ahc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32474867-62d1-43fe-a818-47ef322016d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_AHC)(data_n, n, dist, link) \n",
    "    for n, (dist, link) in tqdm(ahc_grid, desc='Fitting AHC models'))\n",
    "\n",
    "ahc_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b26c1c-d087-4f08-84fe-c724be527d65",
   "metadata": {},
   "source": [
    "## 1.4. HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0f087-2870-4ea9-9b31-c1fe9ab3288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ['manhattan', 'euclidean', 'chebyshev', 'mahalanobis', 'hamming']\n",
    "min_cluster_sizes = range(2, 16)\n",
    "min_samples_range = range(1, 16)\n",
    "hdb_params = product(distances, min_cluster_sizes, min_samples_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d6adc-55fe-43cf-9fc0-0b6e4dc98031",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_hdbscan)(data_n, dist, min_clust, min_smpl)\n",
    "    for dist, min_clust, min_smpl in tqdm(hdb_params, desc='Fitting HDBSCAN models'))\n",
    "\n",
    "hdbscan_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd77545-5713-4fe0-970c-11c4d346a180",
   "metadata": {},
   "source": [
    "## 1.5. Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce063cf-1433-4461-851a-646030af0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.concat([latent_all, kmeans_all, ahc_all, hdbscan_all]).reset_index(drop=True)\n",
    "all_models.to_csv(f\"output/models/all_models_{approach}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8e1dc-5d1b-415a-b51f-a7b75be5ca46",
   "metadata": {},
   "source": [
    "# 2. Gap statistics for latent models, kmeans and AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a01e25-6da4-4f9a-ac5c-681fe87b4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.concat([latent_all, kmeans_all, ahc_all]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726f137-707b-4c61-9b88-04f607d25026",
   "metadata": {},
   "source": [
    "## Step 1: compute the gap statistic for each model-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed8683-ac4a-4048-a5a7-4d31e355fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kmeans': kmeans_params,\n",
    "    'AHC': ahc_params,\n",
    "    'latent': latent_params}\n",
    "\n",
    "param_names = {\n",
    "    'kmeans': ['dist', 'link'],\n",
    "    'AHC': ['dist', 'link'],\n",
    "    'latent': ['msrt', 'covar']}\n",
    "\n",
    "models = ['kmeans', 'AHC', 'latent']\n",
    "\n",
    "bootstrap_grid = [\n",
    "    (model, {key: value for key, value in zip(param_names[model], param_values)}, n_val, n_iter)\n",
    "    for model in models\n",
    "    for param_values in params[model]\n",
    "    for n_val in (range(1, max_clust+1) if model == 'latent' else range(2, max_clust+1))\n",
    "    for n_iter in range(gap_iters)]\n",
    "\n",
    "model_grid = [\n",
    "    (model, dict(zip(param_names[model], param_values)))\n",
    "    for model in models\n",
    "    for param_values in params[model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fec7cd-3b63-4d4b-bc0d-3752debd1ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(bootstrap_gap)(\n",
    "        data = data_f if model == 'latent' and 'categorical' in config.get('msrt') else data_n,\n",
    "        controls = controls_dum if model == 'latent' and config.get('covar') == 'with' else None,\n",
    "        n = n,\n",
    "        model = model,\n",
    "        params = config,\n",
    "        iter_num = iter_num)\n",
    "    for model, config, n, iter_num in tqdm(bootstrap_grid, desc='Bootstrapping CVIs'))\n",
    "bootstrap_results = pd.concat(results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c3c90-7c39-4a58-adc4-5ed71569a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_results['params'] = bootstrap_results['params'].apply(\n",
    "    lambda d: {k: v for k, v in d.items() if k not in ['NAs', 'wgt']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8cea1-2e68-43d5-90b0-81ee18d68158",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_values = []\n",
    "\n",
    "for model, config in model_grid:\n",
    "    rows_id = ((bootstrap_results['model'] == model) & (bootstrap_results['params'] == config))    \n",
    "    bs_select_res = bootstrap_results[rows_id]\n",
    "    gap_stats = compute_gap(bs_select_res, all_models, model, config, CVI)\n",
    "    gap_values.append(gap_stats)\n",
    "\n",
    "gap_values = pd.concat(gap_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f0eaa-0fbf-4fe5-9459-2f6d251da20e",
   "metadata": {},
   "source": [
    "## Step 2: identify the optimal number of clusters for each model-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad9661-0ffa-4ce3-ba43-d0f5c60a73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to store results\n",
    "cols = ['model', 'params', 'n_clust'] + \\\n",
    "       [index for index in CVI] + \\\n",
    "       [f'{index}_gap' for index in CVI]\n",
    "\n",
    "candidate_models = pd.DataFrame(columns=cols)\n",
    "candidate_models['model'] = candidate_models['model'].astype('object')\n",
    "candidate_models['params'] = candidate_models['params'].astype('object')\n",
    "\n",
    "float_cols = [col for col in cols if col not in ['model', 'params', 'n_clust'] + CVI]\n",
    "candidate_models[float_cols] = candidate_models[float_cols].astype('float64')\n",
    "int_cols = [col for col in cols if col in ['n_clust'] + CVI]\n",
    "candidate_models[int_cols] = candidate_models[int_cols].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95226fed-3e91-4bf2-bc52-6de7cae48c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best n\n",
    "for model, config in model_grid:\n",
    "    for index in CVI:\n",
    "        best_n = get_gap(gap_values, model, config, index)\n",
    "\n",
    "        # Check if a best value has been identified\n",
    "        if best_n != 'none':\n",
    "            row_id = ((candidate_models['model'] == model) & \n",
    "                      (candidate_models['params'] == config) &\n",
    "                      (candidate_models['n_clust'] == best_n))\n",
    "            \n",
    "            # Check if the corresponding row exists in the df\n",
    "            if candidate_models[row_id].empty:\n",
    "\n",
    "                model_id = ((all_models['model'] == model) & \n",
    "                           (all_models['params'] == config) &\n",
    "                           (all_models['n_clust'] == best_n))\n",
    "                \n",
    "                new_row = {\n",
    "                    'model': model,\n",
    "                    'params': config,\n",
    "                    'n_clust': best_n,\n",
    "                    'min_clust_size': all_models.loc[model_id, 'min_clust_size'].values[0],\n",
    "                    'max_clust_size': all_models.loc[model_id, 'max_clust_size'].values[0],\n",
    "                    'silhouette': all_models.loc[model_id, 'silhouette'].values[0],\n",
    "                    'calinski_harabasz': all_models.loc[model_id, 'calinski_harabasz'].values[0],\n",
    "                    'davies_bouldin': all_models.loc[model_id, 'davies_bouldin'].values[0],\n",
    "                    'dunn': all_models.loc[model_id, 'dunn'].values[0],\n",
    "                    f'{index}_gap': 1}\n",
    "                \n",
    "                new_row = pd.DataFrame([new_row])\n",
    "                candidate_models = pd.concat([candidate_models, new_row], ignore_index=True)\n",
    "\n",
    "            # Otherwise, update the existing row\n",
    "            else:\n",
    "                candidate_models.loc[row_id, f'{index}_gap'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e41c5-b33b-4b36-8a65-f8ad24670dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_models.to_csv(f\"output/models/candidate_models_{approach}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5cf13-056e-4e5c-aa0e-b5e5734be64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {(time.time() - time0)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6234d51-e2e2-4fdf-a37e-e7f8904ad477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
