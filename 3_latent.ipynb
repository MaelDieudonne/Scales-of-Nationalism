{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stepmix.bootstrap import blrt_sweep\n",
    "from stepmix.stepmix import StepMix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model_fit import do_StepMix\n",
    "from src.model_select import elbow_method, lrt, blrt_sweep_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVI = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "max_threads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28820ec-976b-4d7b-92f4-62c50eb66c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [\n",
    "    'clseusa', 'ambornin', 'amcit', 'amlived', 'amenglsh', 'amchrstn',\n",
    "    'amgovt', 'amfeel', 'amcitizn', 'amshamed', 'belikeus', 'ambetter',\n",
    "    'ifwrong', 'proudsss', 'proudgrp', 'proudpol', 'prouddem', 'proudeco',\n",
    "    'proudspt', 'proudart', 'proudhis', 'proudmil', 'proudsci']\n",
    "\n",
    "var_list_f = [var + \"_f\" for var in var_list]\n",
    "var_list_n = [var + \"_n\" for var in var_list]\n",
    "\n",
    "ctrl_list = [\n",
    "    'party_f', 'race_f', 'educ_f', 'region_f', 'reltrad_f', 'religstr_f', \n",
    "    'born_usa_f', 'sex_f', 'age_n', 'lnrealinc2004_n', 'age_n', 'lnrealinc2004_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e767a2f-4830-453c-a044-bcd771b288ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2004 = pd.read_parquet(f\"data/data2004_replic.parquet\")\n",
    "data2004 = pd.read_parquet(f\"data/data2004_own.parquet\")\n",
    "data2004_ni = pd.read_parquet(f\"data/data2004_replic_ni.parquet\")\n",
    "\n",
    "# Datasets with numeric outcomes\n",
    "data_n = data2004[var_list_n]\n",
    "data_n = StandardScaler().fit_transform(data_n)\n",
    "data_n = pd.DataFrame(data_n)\n",
    "\n",
    "data_ni_n = data2004[var_list_n]\n",
    "data_ni_n = StandardScaler().fit_transform(data_ni_n)\n",
    "data_ni_n = pd.DataFrame(data_ni_n)\n",
    "\n",
    "# Dataset with categorical outcomes and reindexing to 0 (as expected by StepMix)\n",
    "data_f = data2004[var_list_n] - 1\n",
    "data_ni_f = data2004_ni[var_list_n] - 1\n",
    "\n",
    "# Dataset with controls (same as the authors)\n",
    "controls = data2004[ctrl_list]\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "\n",
    "# Sample weights\n",
    "weights = data2004['wgt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa98bed-4d02-4944-88bb-f50e0c2b9e84",
   "metadata": {},
   "source": [
    "# Replication\n",
    "\n",
    "The authors perform LCA with 1 to 8 classes with missing data, sociodemographic covariates, and sample weights. Do we get similar results with the [StepMix](https://stepmix.readthedocs.io/en/latest/api.html#stepmix) package?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14613873-d1cd-45ba-b54f-410e8e64b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_StepMix)(\n",
    "        data = data_ni_f,\n",
    "        controls = controls_dum,\n",
    "        n = n_clust,\n",
    "        msrt = 'categorical_nan',\n",
    "        covar = 'with',\n",
    "        weights = weights)\n",
    "    for n_clust in tqdm(range(1,9), desc='Fitting latent models'))\n",
    "\n",
    "replic_LCA = pd.DataFrame(results).drop(columns = ['model', 'params', 'silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn'])\n",
    "replic_LCA['l2_red'] = 100 * (replic_LCA['LL'].iloc[0] - replic_LCA['LL']) / replic_LCA['LL'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b804a70-31dd-4723-945d-aa950c0e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "replic_LCA.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38004b-d35e-41e0-8c49-64a39a8cc718",
   "metadata": {},
   "source": [
    "## Absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b334432-9f43-4677-87b5-e511f3128ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aic = replic_LCA.sort_values('aic', ascending=True).iloc[0]\n",
    "best_bic = replic_LCA.sort_values('bic', ascending=True).iloc[0]\n",
    "best_sabic = replic_LCA.sort_values('sabic', ascending=True).iloc[0]\n",
    "best_entropy = replic_LCA.sort_values('relative_entropy', ascending=False).iloc[0]\n",
    "\n",
    "print(f\"Best model according to the min/max rule applied to...\")\n",
    "print(f\"- AIC (min) has {best_aic['n_clust']:.0f} clusters\")\n",
    "print(f\"- BIC (min) has {best_bic['n_clust']:.0f} clusters\")\n",
    "print(f\"- SABIC (min) has {best_sabic['n_clust']:.0f} clusters\")\n",
    "print(f\"- Relative entropy (max) has {best_entropy['n_clust']:.0f} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da20835-ae01-4886-87d0-f2edce74995a",
   "metadata": {},
   "source": [
    "## Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28df757-5ae1-4482-8892-237f77100c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aic = elbow_method(replic_LCA, 'aic')\n",
    "best_bic = elbow_method(replic_LCA, 'bic')\n",
    "best_sabic = elbow_method(replic_LCA, 'sabic')\n",
    "best_entropy = elbow_method(replic_LCA, 'relative_entropy')\n",
    "\n",
    "print(f\"Best model according to the Elbow method applied to...\")\n",
    "\n",
    "if best_aic is None: print(\"- AIC is None\")\n",
    "else: print(f\"- AIC has {best_aic} clusters\")\n",
    "\n",
    "if best_bic is None: print(\"- BIC is None\")\n",
    "else: print(f\"- BIC has {best_bic} clusters\")\n",
    "\n",
    "if best_sabic is None: print(\"- SABIC is None\")\n",
    "else: print(f\"- SABIC has {best_sabic} clusters\")\n",
    "    \n",
    "if best_entropy is None: print(\"- Entropy is None\")\n",
    "else: print(f\"- Entropy has {best_entropy} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86e758-5290-47bf-a3e5-f257f4df5db5",
   "metadata": {},
   "source": [
    "## LRT\n",
    "*LRT - not advisable for comparing models with $k$ and $k-1$ classes as the resulting test statistics does not follow the $\\chi^2$ distribution under the null hypothesis. The implementation below compare models to the 1-class model, which is sometimes recommended, without a formal justification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216cda3-0aac-450c-8593-26f9cb07502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRT = lrt(replic_LCA)\n",
    "LRT = LRT.iloc[1:].reset_index(drop=True)\n",
    "LRT.style.hide(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54021ebe-9437-4506-b150-e387fdef6a11",
   "metadata": {},
   "source": [
    "## BLRT\n",
    "### Without covariates and sample weights\n",
    "Default StepMix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50389e-e170-4393-911a-7ec72cd9ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 500}\n",
    "\n",
    "latent_mod = StepMix(\n",
    "    measurement = 'categorical_nan',\n",
    "    n_init = 7,\n",
    "    abs_tol = 1e-4,\n",
    "    rel_tol = 1e-4,\n",
    "    init_params = 'random',\n",
    "    structural_params = opt_params,\n",
    "    progress_bar = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f5f47-c871-4e62-87e8-ab13f3b7325b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "BLRT = blrt_sweep(\n",
    "    latent_mod,\n",
    "    data_ni_f,\n",
    "    low = 1,\n",
    "    high = 8,\n",
    "    n_repetitions = 500)\n",
    "e_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b06de4-27c0-4cb3-858b-5ed6d1fdcd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {(e_time - s_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d7fb0-14be-4025-bec7-a98cfc01c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLRT_res = pd.concat([pd.DataFrame({'p': [np.nan]}), BLRT]).reset_index(drop=True) # Add a row for the saturated model\n",
    "BLRT_res[\"n clust\"] = [f\"{i+1} vs. {i} clust\" for i in BLRT_res.index]\n",
    "BLRT_res = BLRT_res.iloc[1:]\n",
    "BLRT_res = BLRT_res[[\"n clust\", \"p\"]]\n",
    "BLRT_res.to_csv(\"output/models/BLRT_simplex.csv\", index=False)\n",
    "\n",
    "BLRT_res.style.hide(axis=0).format({\"p\": \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52be3de-aa6c-4a82-b77e-a4fccf6f8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BLRT_res[BLRT_res['p'] > 0.05].empty:\n",
    "    best_LCA = None\n",
    "else:\n",
    "    best_LCA = BLRT_res[BLRT_res['p'] > 0.05]\n",
    "    best_LCA = best_LCA.index[0]\n",
    "\n",
    "print(f\"Optimal number of clusters for LCA without covariates and sample weights is {best_LCA} according to BLRT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf745ff-64c4-46fb-8449-65d24d5a3391",
   "metadata": {},
   "source": [
    "### With covariates and sample weights\n",
    "Custom implementation as the wrapper function provided by StepMix does not allow for sample weights. It is much slower and yields opposite results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e39892-495e-42c1-a9b7-f56b4fa6b06a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 500,}\n",
    "\n",
    "latent_mod = StepMix(\n",
    "    measurement = 'categorical_nan',\n",
    "    n_init = 7,\n",
    "    abs_tol = 1e-4,\n",
    "    rel_tol = 1e-4,\n",
    "    init_params = 'random',\n",
    "    structural = 'covariate',\n",
    "    structural_params = opt_params,\n",
    "    progress_bar = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfedfeb0-4352-4a3c-affb-7dec86108e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "BLRT = blrt_sweep_custom(\n",
    "    latent_mod,\n",
    "    data_ni_f,\n",
    "    controls_dum,\n",
    "    sample_weight = weights,\n",
    "    low = 1,\n",
    "    high = 8,\n",
    "    n_repetitions = 500,\n",
    "    n_jobs = max_threads)\n",
    "e_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19211cf0-6738-433e-aa23-c83854020029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {(e_time - s_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b9d50-04c0-4128-bce1-cc2961d94f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BLRT_res = pd.concat([pd.DataFrame({'p': [np.nan]}), BLRT]).reset_index(drop=True) # Add a row for the saturated model\n",
    "BLRT_res[\"n clust\"] = [f\"{i+1} vs. {i} clust\" for i in BLRT_res.index]\n",
    "BLRT_res = BLRT_res.iloc[1:]\n",
    "BLRT_res = BLRT_res[[\"n clust\", \"p\"]]\n",
    "BLRT_res.to_csv(\"output/models/BLRT_complex.csv\", index=False)\n",
    "\n",
    "BLRT_res.style.hide(axis=0).format({\"p\": \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f574a71-b674-4fb5-a395-4b2d2969c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BLRT_res[BLRT_res['p'] > 0.05].empty:\n",
    "    best_LCA = None\n",
    "else:\n",
    "    best_LCA = BLRT_res[BLRT_res['p'] > 0.05]\n",
    "    best_LCA = best_LCA.index[0]\n",
    "\n",
    "print(f\"Optimal number of clusters for LCA with covariates and sample weights is {best_LCA} according to BLRT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7062a2-2baf-4263-9acf-b9bc7f8200a5",
   "metadata": {},
   "source": [
    "# Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63d684-cd9c-43f6-9e4d-f457752063f6",
   "metadata": {},
   "source": [
    "Compare models...\n",
    "- Categorical (= LCA) or continuous (= LPA / GMM)\n",
    "- With missing or imputed values\n",
    "- With or without survey weights\n",
    "- With or without covariates\n",
    "\n",
    "Regarding LPA...\n",
    "- `gaussian_diag_nan` does not converge and `gaussian_diag` tends to overfit. Hence the use of `gaussian_spherical`, which is less flexible. \n",
    "- Convergence becomes problematic for LPA above 13-14 classes, making scaling is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc76e10-4c0b-4829-98d9-1307ca486931",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = ['categorical', 'continuous']\n",
    "missing_values = ['without', 'with']\n",
    "covariates = ['without', 'with']\n",
    "sample_weights = ['without', 'with']\n",
    "\n",
    "max_clust = 16\n",
    "clust_range = range(1, max_clust+1)\n",
    "latent_params = list(product(measurements, missing_values, covariates, sample_weights))\n",
    "latent_grid = product(clust_range, latent_params)\n",
    "\n",
    "def set_data(msrt, NAs):\n",
    "    if msrt == 'categorical' and NAs == 'with':\n",
    "        return data_ni_f\n",
    "    elif msrt == 'categorical' and NAs == 'without':\n",
    "        return data_f\n",
    "    elif msrt == 'continuous' and NAs == 'with':\n",
    "        return data_ni_n\n",
    "    elif msrt == 'continuous' and NAs == 'without':\n",
    "        return data_n\n",
    "\n",
    "def set_measurement(msrt, NAs):\n",
    "    if msrt == 'categorical' and NAs == 'with':\n",
    "        return 'categorical_nan'\n",
    "    elif msrt == 'categorical' and NAs == 'without':\n",
    "        return 'categorical'\n",
    "    elif msrt == 'continuous' and NAs == 'with':\n",
    "        return 'gaussian_spherical_nan'\n",
    "    elif msrt == 'continuous' and NAs == 'without':\n",
    "        return 'gaussian_spherical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a46013-27ca-46c9-bc6a-f9b44aa2f9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs = max_threads)(\n",
    "    delayed(do_StepMix)(\n",
    "        data = set_data(msrt, NAs),\n",
    "        controls = controls_dum if covar == 'with' else None,\n",
    "        n = n_clust,\n",
    "        msrt = set_measurement(msrt, NAs), \n",
    "        covar = covar,\n",
    "        weights = weights if wgt == 'with' else None)\n",
    "    for n_clust, (msrt, NAs, covar, wgt) in tqdm(latent_grid, desc = 'Fitting latent models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d31713-100d-495a-9c09-4f5ce247c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_all = pd.DataFrame(results)\n",
    "\n",
    "LCA = latent_all[latent_all['params'].apply(lambda x: 'categorical' in x.get('msrt', ''))]\n",
    "LPA = latent_all[latent_all['params'].apply(lambda x: 'gaussian' in x.get('msrt', ''))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942c6fa-1dd3-4e0e-9dbf-2c1cc36a50f6",
   "metadata": {},
   "source": [
    "## LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c5a63-2f4c-4693-be65-8723dcab35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(param_dict):\n",
    "    return f\"msrt:{param_dict.get('msrt')}, NAs:{param_dict.get('NAs')}, covar:{param_dict.get('covar')}, wgt:{param_dict.get('wgt')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65257a-5912-49f2-a3fc-ffdd36588711",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1_metrics = ['sabic', 'aic', 'classif_error', 'LL']\n",
    "row2_metrics = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = row1_metrics + row2_metrics\n",
    "\n",
    "LCA.loc[:, 'label'] = LCA['params'].apply(extract_label)\n",
    "\n",
    "# Create a 3-row x 4-column grid\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(22, 18), sharex=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot metrics in first 8 axes\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    for label, group in LCA.groupby('label'):\n",
    "        group = group.sort_values('n_clust')\n",
    "        ax.plot(group['n_clust'], group[metric], marker='', label=label)\n",
    "    ax.set_title(metric.upper())\n",
    "    ax.set_xlabel(\"Number of Clusters\")\n",
    "    ax.set_ylabel(metric.upper())\n",
    "\n",
    "# Hide any unused subplot (in case)\n",
    "for j in range(8, 12):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Legend in the entire third row (axes 8 to 11 merged)\n",
    "# Remove the 4 axes in row 3 and create one big axis there:\n",
    "for ax in axes[8:12]:\n",
    "    fig.delaxes(ax)\n",
    "legend_ax = fig.add_subplot(3,1,3)  # new axis spanning entire bottom row\n",
    "\n",
    "legend_ax.axis('off')  # no axis lines or ticks\n",
    "\n",
    "# Create dummy lines for legend from any group (using first group)\n",
    "first_label = next(iter(LCA['label'].unique()))\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "for label, group in LCA.groupby('label'):\n",
    "    line, = legend_ax.plot([], [], marker='o', label=label)\n",
    "    lines.append(line)\n",
    "    labels.append(label)\n",
    "\n",
    "legend_ax.legend(lines, labels, loc='center', ncol=4, title=\"Combination\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "fig.suptitle(\"Model Fit and Clustering Metrics vs. Number of Clusters\", fontsize=16, y=0.98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647f6e7-0fe0-4d07-b927-45d794a51022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your metric groups\n",
    "metrics_row1 = ['aic', 'classif_error', 'LL', 'sabic']\n",
    "metrics_row2 = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = metrics_row1 + metrics_row2\n",
    "\n",
    "maximize_metrics = {'LL', 'silhouette', 'calinski_harabasz'}\n",
    "marker_styles = ['D', '*']  # diamond = best, star = 2nd best\n",
    "marker_alpha = [0.5, 0.8]\n",
    "marker_size = [90, 80]\n",
    "LCA.loc[:, 'label'] = LCA['params'].apply(extract_label)\n",
    "unique_labels = LCA['label'].unique()\n",
    "colors = {label: plt.cm.tab20(i % 20) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Set up GridSpec with 3 rows: 2 for plots, 1 for legend\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "gs = gridspec.GridSpec(3, 4, height_ratios=[1, 1, 0.1])  # last row is for legend\n",
    "\n",
    "axes = [fig.add_subplot(gs[i // 4, i % 4]) for i in range(8)]\n",
    "\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    maximize = metric in maximize_metrics\n",
    "\n",
    "    df_metric = LCA.dropna(subset=[metric])\n",
    "\n",
    "    sorted_df = (\n",
    "        df_metric\n",
    "        .sort_values(metric, ascending=not maximize)\n",
    "        .groupby(\"n_clust\")\n",
    "        .head(2)\n",
    "        .copy()\n",
    "    )\n",
    "    sorted_df['rank'] = sorted_df.groupby('n_clust').cumcount()\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        marker = marker_styles[row['rank']]\n",
    "        alpha = marker_alpha[row['rank']]\n",
    "        size = marker_size[row['rank']]\n",
    "        ax.scatter(\n",
    "            row['n_clust'], row[metric],\n",
    "            color=colors[row['label']],\n",
    "            marker=marker,\n",
    "            alpha=alpha,\n",
    "            s=size,\n",
    "            label=row['label'] if row['rank'] == 0 else None\n",
    "        )\n",
    "\n",
    "    title = \"Classification error\" if metric == 'classif_error' else metric\n",
    "    ax.set_title(title.upper())\n",
    "    # ax.set_xlabel(\"Number of Clusters\")\n",
    "    # ax.set_ylabel(metric.upper())\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "# Create an extra subplot just for the legend\n",
    "legend_ax = fig.add_subplot(gs[2, :])  # full width on third row\n",
    "legend_ax.axis('off')\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='o', linestyle='None',\n",
    "               color=colors[label], label=label)\n",
    "    for label in unique_labels\n",
    "]\n",
    "legend_ax.legend(handles=legend_handles, loc='center', ncol=4, title=\"Params\", fontsize='medium')\n",
    "\n",
    "plt.suptitle(\"Top 2 Models per Number of Clusters Across Metrics\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c143b4-f7ff-4f99-9d7f-0ab82ae7a444",
   "metadata": {},
   "source": [
    "## LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde0e39-2a90-4715-9a7d-f68fa7413053",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1_metrics = ['sabic', 'aic', 'classif_error', 'LL']\n",
    "row2_metrics = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = row1_metrics + row2_metrics\n",
    "\n",
    "LPA.loc[:, 'label'] = LPA['params'].apply(extract_label)\n",
    "\n",
    "# Create a 3-row x 4-column grid\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(22, 18), sharex=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot metrics in first 8 axes\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    for label, group in LPA.groupby('label'):\n",
    "        group = group.sort_values('n_clust')\n",
    "        ax.plot(group['n_clust'], group[metric], marker='', label=label)\n",
    "    ax.set_title(metric.upper())\n",
    "    ax.set_xlabel(\"Number of Clusters\")\n",
    "    ax.set_ylabel(metric.upper())\n",
    "\n",
    "# Hide any unused subplot (in case)\n",
    "for j in range(8, 12):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Legend in the entire third row (axes 8 to 11 merged)\n",
    "# Remove the 4 axes in row 3 and create one big axis there:\n",
    "for ax in axes[8:12]:\n",
    "    fig.delaxes(ax)\n",
    "legend_ax = fig.add_subplot(3,1,3)  # new axis spanning entire bottom row\n",
    "\n",
    "legend_ax.axis('off')  # no axis lines or ticks\n",
    "\n",
    "# Create dummy lines for legend from any group (using first group)\n",
    "first_label = next(iter(LPA['label'].unique()))\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "for label, group in LPA.groupby('label'):\n",
    "    line, = legend_ax.plot([], [], marker='o', label=label)\n",
    "    lines.append(line)\n",
    "    labels.append(label)\n",
    "\n",
    "legend_ax.legend(lines, labels, loc='center', ncol=4, title=\"Combination\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "fig.suptitle(\"Model Fit and Clustering Metrics vs. Number of Clusters\", fontsize=16, y=0.98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f6956-912e-4861-823f-3920acd29fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your metric groups\n",
    "metrics_row1 = ['aic', 'classif_error', 'LL', 'sabic']\n",
    "metrics_row2 = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = metrics_row1 + metrics_row2\n",
    "\n",
    "maximize_metrics = {'LL', 'silhouette', 'calinski_harabasz'}\n",
    "marker_styles = ['D', '*']  # diamond = best, star = 2nd best\n",
    "marker_alpha = [0.5, 0.8]\n",
    "marker_size = [90, 80]\n",
    "LPA.loc[:, 'label'] = LPA['params'].apply(extract_label)\n",
    "unique_labels = LPA['label'].unique()\n",
    "colors = {label: plt.cm.tab20(i % 20) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Set up GridSpec with 3 rows: 2 for plots, 1 for legend\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "gs = gridspec.GridSpec(3, 4, height_ratios=[1, 1, 0.1])  # last row is for legend\n",
    "\n",
    "axes = [fig.add_subplot(gs[i // 4, i % 4]) for i in range(8)]\n",
    "\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    maximize = metric in maximize_metrics\n",
    "\n",
    "    df_metric = LPA.dropna(subset=[metric])\n",
    "\n",
    "    sorted_df = (\n",
    "        df_metric\n",
    "        .sort_values(metric, ascending=not maximize)\n",
    "        .groupby(\"n_clust\")\n",
    "        .head(2)\n",
    "        .copy()\n",
    "    )\n",
    "    sorted_df['rank'] = sorted_df.groupby('n_clust').cumcount()\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        marker = marker_styles[row['rank']]\n",
    "        alpha = marker_alpha[row['rank']]\n",
    "        size = marker_size[row['rank']]\n",
    "        ax.scatter(\n",
    "            row['n_clust'], row[metric],\n",
    "            color=colors[row['label']],\n",
    "            marker=marker,\n",
    "            alpha=alpha,\n",
    "            s=size,\n",
    "            label=row['label'] if row['rank'] == 0 else None\n",
    "        )\n",
    "\n",
    "    title = \"Classification error\" if metric == 'classif_error' else metric\n",
    "    ax.set_title(title.upper())\n",
    "    # ax.set_xlabel(\"Number of Clusters\")\n",
    "    # ax.set_ylabel(metric.upper())\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "# Create an extra subplot just for the legend\n",
    "legend_ax = fig.add_subplot(gs[2, :])  # full width on third row\n",
    "legend_ax.axis('off')\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='o', linestyle='None',\n",
    "               color=colors[label], label=label)\n",
    "    for label in unique_labels\n",
    "]\n",
    "legend_ax.legend(handles=legend_handles, loc='center', ncol=4, title=\"Params\", fontsize='medium')\n",
    "\n",
    "plt.suptitle(\"Top 2 Models per Number of Clusters Across Metrics\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
