{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stepmix.bootstrap import blrt_sweep\n",
    "from stepmix.stepmix import StepMix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model_fit import do_StepMix\n",
    "from src.model_select import elbow_method, lrt, blrt_sweep_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58bc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVI = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "max_threads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28820ec-976b-4d7b-92f4-62c50eb66c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [\n",
    "    'clseusa', 'ambornin', 'amcit', 'amlived', 'amenglsh', 'amchrstn',\n",
    "    'amgovt', 'amfeel', 'amcitizn', 'amshamed', 'belikeus', 'ambetter',\n",
    "    'ifwrong', 'proudsss', 'proudgrp', 'proudpol', 'prouddem', 'proudeco',\n",
    "    'proudspt', 'proudart', 'proudhis', 'proudmil', 'proudsci']\n",
    "\n",
    "var_list_f = [var + \"_f\" for var in var_list]\n",
    "var_list_n = [var + \"_n\" for var in var_list]\n",
    "\n",
    "ctrl_list = [\n",
    "    'party_f', 'race_f', 'educ_f', 'region_f', 'reltrad_f', 'religstr_f', \n",
    "    'born_usa_f', 'sex_f', 'age_n', 'lnrealinc2004_n', 'age_n', 'lnrealinc2004_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e767a2f-4830-453c-a044-bcd771b288ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2004 = pd.read_parquet(f\"data/data2004_replic.parquet\")\n",
    "data2004 = pd.read_parquet(f\"data/data2004_830.parquet\")\n",
    "data2004_ni = pd.read_parquet(f\"data/data2004_830_ni.parquet\")\n",
    "\n",
    "# Datasets with numeric outcomes\n",
    "data_n = data2004[var_list_n]\n",
    "data_n = StandardScaler().fit_transform(data_n)\n",
    "data_n = pd.DataFrame(data_n)\n",
    "\n",
    "data_ni_n = data2004[var_list_n]\n",
    "data_ni_n = StandardScaler().fit_transform(data_ni_n)\n",
    "data_ni_n = pd.DataFrame(data_ni_n)\n",
    "\n",
    "# Dataset with categorical outcomes and reindexing to 0 (as expected by StepMix)\n",
    "data_f = data2004[var_list_n] - 1\n",
    "data_ni_f = data2004_ni[var_list_n] - 1\n",
    "\n",
    "# Dataset with controls (same as the authors)\n",
    "controls = data2004[ctrl_list]\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "\n",
    "# Sample weights\n",
    "weights = data2004['wgt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa98bed-4d02-4944-88bb-f50e0c2b9e84",
   "metadata": {},
   "source": [
    "# Replication\n",
    "\n",
    "The authors perform LCA with 1 to 8 classes with missing data, sociodemographic covariates, and sample weights. Do we get similar results with the [StepMix](https://stepmix.readthedocs.io/en/latest/api.html#stepmix) package?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14613873-d1cd-45ba-b54f-410e8e64b571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting latent models: 100%|██████████| 8/8 [00:00<00:00, 171.67it/s]\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_StepMix)(\n",
    "        data = data_ni_f,\n",
    "        controls = controls_dum,\n",
    "        n = n_clust,\n",
    "        msrt = 'categorical_nan',\n",
    "        covar = 'with',\n",
    "        weights = weights)\n",
    "    for n_clust in tqdm(range(1,9), desc='Fitting latent models'))\n",
    "\n",
    "replic_LCA = pd.DataFrame(results).drop(columns = ['model', 'params', 'silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn'])\n",
    "replic_LCA['l2_red'] = 100 * (replic_LCA['LL'].iloc[0] - replic_LCA['LL']) / replic_LCA['LL'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b804a70-31dd-4723-945d-aa950c0e5938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e418d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e418d_level0_col0\" class=\"col_heading level0 col0\" >n_clust</th>\n",
       "      <th id=\"T_e418d_level0_col1\" class=\"col_heading level0 col1\" >min_clust_size</th>\n",
       "      <th id=\"T_e418d_level0_col2\" class=\"col_heading level0 col2\" >max_clust_size</th>\n",
       "      <th id=\"T_e418d_level0_col3\" class=\"col_heading level0 col3\" >aic</th>\n",
       "      <th id=\"T_e418d_level0_col4\" class=\"col_heading level0 col4\" >bic</th>\n",
       "      <th id=\"T_e418d_level0_col5\" class=\"col_heading level0 col5\" >sabic</th>\n",
       "      <th id=\"T_e418d_level0_col6\" class=\"col_heading level0 col6\" >relative_entropy</th>\n",
       "      <th id=\"T_e418d_level0_col7\" class=\"col_heading level0 col7\" >classif_error</th>\n",
       "      <th id=\"T_e418d_level0_col8\" class=\"col_heading level0 col8\" >df</th>\n",
       "      <th id=\"T_e418d_level0_col9\" class=\"col_heading level0 col9\" >LL</th>\n",
       "      <th id=\"T_e418d_level0_col10\" class=\"col_heading level0 col10\" >l2_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e418d_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_e418d_row0_col1\" class=\"data row0 col1\" >830</td>\n",
       "      <td id=\"T_e418d_row0_col2\" class=\"data row0 col2\" >830</td>\n",
       "      <td id=\"T_e418d_row0_col3\" class=\"data row0 col3\" >38337.224411</td>\n",
       "      <td id=\"T_e418d_row0_col4\" class=\"data row0 col4\" >38686.609913</td>\n",
       "      <td id=\"T_e418d_row0_col5\" class=\"data row0 col5\" >38948.997530</td>\n",
       "      <td id=\"T_e418d_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_e418d_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "      <td id=\"T_e418d_row0_col8\" class=\"data row0 col8\" >74.000000</td>\n",
       "      <td id=\"T_e418d_row0_col9\" class=\"data row0 col9\" >-23.005557</td>\n",
       "      <td id=\"T_e418d_row0_col10\" class=\"data row0 col10\" >-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e418d_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_e418d_row1_col1\" class=\"data row1 col1\" >278</td>\n",
       "      <td id=\"T_e418d_row1_col2\" class=\"data row1 col2\" >552</td>\n",
       "      <td id=\"T_e418d_row1_col3\" class=\"data row1 col3\" >36239.901860</td>\n",
       "      <td id=\"T_e418d_row1_col4\" class=\"data row1 col4\" >37108.644189</td>\n",
       "      <td id=\"T_e418d_row1_col5\" class=\"data row1 col5\" >37761.067453</td>\n",
       "      <td id=\"T_e418d_row1_col6\" class=\"data row1 col6\" >0.858332</td>\n",
       "      <td id=\"T_e418d_row1_col7\" class=\"data row1 col7\" >0.040978</td>\n",
       "      <td id=\"T_e418d_row1_col8\" class=\"data row1 col8\" >184.000000</td>\n",
       "      <td id=\"T_e418d_row1_col9\" class=\"data row1 col9\" >-21.609579</td>\n",
       "      <td id=\"T_e418d_row1_col10\" class=\"data row1 col10\" >6.068001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e418d_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_e418d_row2_col1\" class=\"data row2 col1\" >142</td>\n",
       "      <td id=\"T_e418d_row2_col2\" class=\"data row2 col2\" >366</td>\n",
       "      <td id=\"T_e418d_row2_col3\" class=\"data row2 col3\" >35505.252173</td>\n",
       "      <td id=\"T_e418d_row2_col4\" class=\"data row2 col4\" >36893.351329</td>\n",
       "      <td id=\"T_e418d_row2_col5\" class=\"data row2 col5\" >37935.810241</td>\n",
       "      <td id=\"T_e418d_row2_col6\" class=\"data row2 col6\" >0.863578</td>\n",
       "      <td id=\"T_e418d_row2_col7\" class=\"data row2 col7\" >0.059555</td>\n",
       "      <td id=\"T_e418d_row2_col8\" class=\"data row2 col8\" >294.000000</td>\n",
       "      <td id=\"T_e418d_row2_col9\" class=\"data row2 col9\" >-21.034489</td>\n",
       "      <td id=\"T_e418d_row2_col10\" class=\"data row2 col10\" >8.567789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e418d_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_e418d_row3_col1\" class=\"data row3 col1\" >129</td>\n",
       "      <td id=\"T_e418d_row3_col2\" class=\"data row3 col2\" >314</td>\n",
       "      <td id=\"T_e418d_row3_col3\" class=\"data row3 col3\" >35112.055618</td>\n",
       "      <td id=\"T_e418d_row3_col4\" class=\"data row3 col4\" >37019.511602</td>\n",
       "      <td id=\"T_e418d_row3_col5\" class=\"data row3 col5\" >38452.006160</td>\n",
       "      <td id=\"T_e418d_row3_col6\" class=\"data row3 col6\" >0.878059</td>\n",
       "      <td id=\"T_e418d_row3_col7\" class=\"data row3 col7\" >0.065965</td>\n",
       "      <td id=\"T_e418d_row3_col8\" class=\"data row3 col8\" >404.000000</td>\n",
       "      <td id=\"T_e418d_row3_col9\" class=\"data row3 col9\" >-20.665094</td>\n",
       "      <td id=\"T_e418d_row3_col10\" class=\"data row3 col10\" >10.173469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e418d_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_e418d_row4_col1\" class=\"data row4 col1\" >60</td>\n",
       "      <td id=\"T_e418d_row4_col2\" class=\"data row4 col2\" >291</td>\n",
       "      <td id=\"T_e418d_row4_col3\" class=\"data row4 col3\" >34919.905023</td>\n",
       "      <td id=\"T_e418d_row4_col4\" class=\"data row4 col4\" >37346.717833</td>\n",
       "      <td id=\"T_e418d_row4_col5\" class=\"data row4 col5\" >39169.248039</td>\n",
       "      <td id=\"T_e418d_row4_col6\" class=\"data row4 col6\" >0.900723</td>\n",
       "      <td id=\"T_e418d_row4_col7\" class=\"data row4 col7\" >0.061068</td>\n",
       "      <td id=\"T_e418d_row4_col8\" class=\"data row4 col8\" >514.000000</td>\n",
       "      <td id=\"T_e418d_row4_col9\" class=\"data row4 col9\" >-20.416810</td>\n",
       "      <td id=\"T_e418d_row4_col10\" class=\"data row4 col10\" >11.252701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e418d_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_e418d_row5_col1\" class=\"data row5 col1\" >57</td>\n",
       "      <td id=\"T_e418d_row5_col2\" class=\"data row5 col2\" >261</td>\n",
       "      <td id=\"T_e418d_row5_col3\" class=\"data row5 col3\" >34959.153889</td>\n",
       "      <td id=\"T_e418d_row5_col4\" class=\"data row5 col4\" >37905.323526</td>\n",
       "      <td id=\"T_e418d_row5_col5\" class=\"data row5 col5\" >40117.889379</td>\n",
       "      <td id=\"T_e418d_row5_col6\" class=\"data row5 col6\" >0.883546</td>\n",
       "      <td id=\"T_e418d_row5_col7\" class=\"data row5 col7\" >0.080268</td>\n",
       "      <td id=\"T_e418d_row5_col8\" class=\"data row5 col8\" >624.000000</td>\n",
       "      <td id=\"T_e418d_row5_col9\" class=\"data row5 col9\" >-20.307924</td>\n",
       "      <td id=\"T_e418d_row5_col10\" class=\"data row5 col10\" >11.726005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e418d_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_e418d_row6_col1\" class=\"data row6 col1\" >31</td>\n",
       "      <td id=\"T_e418d_row6_col2\" class=\"data row6 col2\" >188</td>\n",
       "      <td id=\"T_e418d_row6_col3\" class=\"data row6 col3\" >34932.508430</td>\n",
       "      <td id=\"T_e418d_row6_col4\" class=\"data row6 col4\" >38398.034895</td>\n",
       "      <td id=\"T_e418d_row6_col5\" class=\"data row6 col5\" >41000.636395</td>\n",
       "      <td id=\"T_e418d_row6_col6\" class=\"data row6 col6\" >0.872202</td>\n",
       "      <td id=\"T_e418d_row6_col7\" class=\"data row6 col7\" >0.095341</td>\n",
       "      <td id=\"T_e418d_row6_col8\" class=\"data row6 col8\" >734.000000</td>\n",
       "      <td id=\"T_e418d_row6_col9\" class=\"data row6 col9\" >-20.159342</td>\n",
       "      <td id=\"T_e418d_row6_col10\" class=\"data row6 col10\" >12.371856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e418d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e418d_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_e418d_row7_col1\" class=\"data row7 col1\" >25</td>\n",
       "      <td id=\"T_e418d_row7_col2\" class=\"data row7 col2\" >217</td>\n",
       "      <td id=\"T_e418d_row7_col3\" class=\"data row7 col3\" >34916.984954</td>\n",
       "      <td id=\"T_e418d_row7_col4\" class=\"data row7 col4\" >38901.868246</td>\n",
       "      <td id=\"T_e418d_row7_col5\" class=\"data row7 col5\" >41894.505393</td>\n",
       "      <td id=\"T_e418d_row7_col6\" class=\"data row7 col6\" >0.890117</td>\n",
       "      <td id=\"T_e418d_row7_col7\" class=\"data row7 col7\" >0.086774</td>\n",
       "      <td id=\"T_e418d_row7_col8\" class=\"data row7 col8\" >844.000000</td>\n",
       "      <td id=\"T_e418d_row7_col9\" class=\"data row7 col9\" >-20.017461</td>\n",
       "      <td id=\"T_e418d_row7_col10\" class=\"data row7 col10\" >12.988584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1320c8380>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replic_LCA.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38004b-d35e-41e0-8c49-64a39a8cc718",
   "metadata": {},
   "source": [
    "## Absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b334432-9f43-4677-87b5-e511f3128ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to the min/max rule applied to...\n",
      "- AIC (min) has 8 clusters\n",
      "- BIC (min) has 3 clusters\n",
      "- SABIC (min) has 2 clusters\n",
      "- Relative entropy (max) has 5 clusters\n"
     ]
    }
   ],
   "source": [
    "best_aic = replic_LCA.sort_values('aic', ascending=True).iloc[0]\n",
    "best_bic = replic_LCA.sort_values('bic', ascending=True).iloc[0]\n",
    "best_sabic = replic_LCA.sort_values('sabic', ascending=True).iloc[0]\n",
    "best_entropy = replic_LCA.sort_values('relative_entropy', ascending=False).iloc[0]\n",
    "\n",
    "print(f\"Best model according to the min/max rule applied to...\")\n",
    "print(f\"- AIC (min) has {best_aic['n_clust']:.0f} clusters\")\n",
    "print(f\"- BIC (min) has {best_bic['n_clust']:.0f} clusters\")\n",
    "print(f\"- SABIC (min) has {best_sabic['n_clust']:.0f} clusters\")\n",
    "print(f\"- Relative entropy (max) has {best_entropy['n_clust']:.0f} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da20835-ae01-4886-87d0-f2edce74995a",
   "metadata": {},
   "source": [
    "## Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28df757-5ae1-4482-8892-237f77100c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model according to the Elbow method applied to...\n",
      "- AIC has 3 clusters\n",
      "- BIC has 2 clusters\n",
      "- SABIC has 2 clusters\n",
      "- Entropy has 2 clusters\n"
     ]
    }
   ],
   "source": [
    "best_aic = elbow_method(replic_LCA, 'aic')\n",
    "best_bic = elbow_method(replic_LCA, 'bic')\n",
    "best_sabic = elbow_method(replic_LCA, 'sabic')\n",
    "best_entropy = elbow_method(replic_LCA, 'relative_entropy')\n",
    "\n",
    "print(f\"Best model according to the Elbow method applied to...\")\n",
    "\n",
    "if best_aic is None: print(\"- AIC is None\")\n",
    "else: print(f\"- AIC has {best_aic} clusters\")\n",
    "\n",
    "if best_bic is None: print(\"- BIC is None\")\n",
    "else: print(f\"- BIC has {best_bic} clusters\")\n",
    "\n",
    "if best_sabic is None: print(\"- SABIC is None\")\n",
    "else: print(f\"- SABIC has {best_sabic} clusters\")\n",
    "    \n",
    "if best_entropy is None: print(\"- Entropy is None\")\n",
    "else: print(f\"- Entropy has {best_entropy} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86e758-5290-47bf-a3e5-f257f4df5db5",
   "metadata": {},
   "source": [
    "## LRT\n",
    "*LRT - not advisable for comparing models with $k$ and $k-1$ classes as the resulting test statistics does not follow the $\\chi^2$ distribution under the null hypothesis. The implementation below compare models to the 1-class model, which is sometimes recommended, without a formal justification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6216cda3-0aac-450c-8593-26f9cb07502a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7aabc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_7aabc_level0_col0\" class=\"col_heading level0 col0\" >n clust</th>\n",
       "      <th id=\"T_7aabc_level0_col1\" class=\"col_heading level0 col1\" >L2 reduction</th>\n",
       "      <th id=\"T_7aabc_level0_col2\" class=\"col_heading level0 col2\" >LR ratio</th>\n",
       "      <th id=\"T_7aabc_level0_col3\" class=\"col_heading level0 col3\" >LR pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_7aabc_row0_col1\" class=\"data row0 col1\" >0.060680</td>\n",
       "      <td id=\"T_7aabc_row0_col2\" class=\"data row0 col2\" >2.791955</td>\n",
       "      <td id=\"T_7aabc_row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "      <td id=\"T_7aabc_row1_col1\" class=\"data row1 col1\" >0.085678</td>\n",
       "      <td id=\"T_7aabc_row1_col2\" class=\"data row1 col2\" >3.942135</td>\n",
       "      <td id=\"T_7aabc_row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_7aabc_row2_col1\" class=\"data row2 col1\" >0.101735</td>\n",
       "      <td id=\"T_7aabc_row2_col2\" class=\"data row2 col2\" >4.680926</td>\n",
       "      <td id=\"T_7aabc_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row3_col0\" class=\"data row3 col0\" >5</td>\n",
       "      <td id=\"T_7aabc_row3_col1\" class=\"data row3 col1\" >0.112527</td>\n",
       "      <td id=\"T_7aabc_row3_col2\" class=\"data row3 col2\" >5.177493</td>\n",
       "      <td id=\"T_7aabc_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row4_col0\" class=\"data row4 col0\" >6</td>\n",
       "      <td id=\"T_7aabc_row4_col1\" class=\"data row4 col1\" >0.117260</td>\n",
       "      <td id=\"T_7aabc_row4_col2\" class=\"data row4 col2\" >5.395266</td>\n",
       "      <td id=\"T_7aabc_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row5_col0\" class=\"data row5 col0\" >7</td>\n",
       "      <td id=\"T_7aabc_row5_col1\" class=\"data row5 col1\" >0.123719</td>\n",
       "      <td id=\"T_7aabc_row5_col2\" class=\"data row5 col2\" >5.692429</td>\n",
       "      <td id=\"T_7aabc_row5_col3\" class=\"data row5 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7aabc_row6_col0\" class=\"data row6 col0\" >8</td>\n",
       "      <td id=\"T_7aabc_row6_col1\" class=\"data row6 col1\" >0.129886</td>\n",
       "      <td id=\"T_7aabc_row6_col2\" class=\"data row6 col2\" >5.976192</td>\n",
       "      <td id=\"T_7aabc_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1320295b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRT = lrt(replic_LCA)\n",
    "LRT = LRT.iloc[1:].reset_index(drop=True)\n",
    "LRT.style.hide(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54021ebe-9437-4506-b150-e387fdef6a11",
   "metadata": {},
   "source": [
    "## BLRT\n",
    "### Without missing values, covariates and sample weights\n",
    "Default StepMix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b50389e-e170-4393-911a-7ec72cd9ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 500}\n",
    "\n",
    "latent_mod = StepMix(\n",
    "    measurement = 'categorical',\n",
    "    n_init = 7,\n",
    "    abs_tol = 1e-4,\n",
    "    rel_tol = 1e-4,\n",
    "    init_params = 'random',\n",
    "    structural_params = opt_params,\n",
    "    progress_bar = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f5f47-c871-4e62-87e8-ab13f3b7325b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1 vs. 2 classes...\n",
      "Bootstrapping null model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [00:12<00:00, 39.93it/s, max_LL=-1.88e+4, median_LL=-1.9e+4, min_LL=-1.93e+4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrapping alternative model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [00:19<00:00, 25.04it/s, max_LL=-1.87e+4, median_LL=-1.9e+4, min_LL=-1.93e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 2 vs. 3 classes...\n",
      "Bootstrapping null model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [00:31<00:00, 15.65it/s, max_LL=-1.75e+4, median_LL=-1.79e+4, min_LL=-1.83e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrapping alternative model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [00:51<00:00,  9.79it/s, max_LL=-1.75e+4, median_LL=-1.79e+4, min_LL=-1.83e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 3 vs. 4 classes...\n",
      "Bootstrapping null model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [00:47<00:00, 10.52it/s, max_LL=-1.71e+4, median_LL=-1.75e+4, min_LL=-1.79e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrapping alternative model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [01:13<00:00,  6.81it/s, max_LL=-1.7e+4, median_LL=-1.74e+4, min_LL=-1.78e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 4 vs. 5 classes...\n",
      "Bootstrapping null model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [2:01:43<00:00, 14.61s/it, max_LL=-1.67e+4, median_LL=-1.72e+4, min_LL=-1.76e+4]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrapping alternative model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    : 100%|██████████| 500/500 [6:59:21<00:00, 50.32s/it, max_LL=-1.67e+4, median_LL=-1.71e+4, min_LL=-1.76e+4]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 5 vs. 6 classes...\n",
      "Bootstrapping null model...\n",
      "\n",
      "Bootstrapping estimator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap Repetitions    :  57%|█████▋    | 285/500 [1:39:51<00:25,  8.52it/s, max_LL=-1.65e+4, median_LL=-1.69e+4, min_LL=-1.74e+4]    "
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "BLRT = blrt_sweep(\n",
    "    latent_mod,\n",
    "    data_f,\n",
    "    low = 1,\n",
    "    high = 8,\n",
    "    n_repetitions = 500)\n",
    "e_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b06de4-27c0-4cb3-858b-5ed6d1fdcd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 12.70 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total execution time: {(e_time - s_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566d7fb0-14be-4025-bec7-a98cfc01c74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6a44b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_6a44b_level0_col0\" class=\"col_heading level0 col0\" >n clust</th>\n",
       "      <th id=\"T_6a44b_level0_col1\" class=\"col_heading level0 col1\" >p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row0_col0\" class=\"data row0 col0\" >2 vs. 1 clust</td>\n",
       "      <td id=\"T_6a44b_row0_col1\" class=\"data row0 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row1_col0\" class=\"data row1 col0\" >3 vs. 2 clust</td>\n",
       "      <td id=\"T_6a44b_row1_col1\" class=\"data row1 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row2_col0\" class=\"data row2 col0\" >4 vs. 3 clust</td>\n",
       "      <td id=\"T_6a44b_row2_col1\" class=\"data row2 col1\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row3_col0\" class=\"data row3 col0\" >5 vs. 4 clust</td>\n",
       "      <td id=\"T_6a44b_row3_col1\" class=\"data row3 col1\" >0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row4_col0\" class=\"data row4 col0\" >6 vs. 5 clust</td>\n",
       "      <td id=\"T_6a44b_row4_col1\" class=\"data row4 col1\" >0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row5_col0\" class=\"data row5 col0\" >7 vs. 6 clust</td>\n",
       "      <td id=\"T_6a44b_row5_col1\" class=\"data row5 col1\" >0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6a44b_row6_col0\" class=\"data row6 col0\" >8 vs. 7 clust</td>\n",
       "      <td id=\"T_6a44b_row6_col1\" class=\"data row6 col1\" >0.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x125101790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLRT_res = pd.concat([pd.DataFrame({'p': [np.nan]}), BLRT]).reset_index(drop=True) # Add a row for the saturated model\n",
    "BLRT_res[\"n clust\"] = [f\"{i+1} vs. {i} clust\" for i in BLRT_res.index]\n",
    "BLRT_res = BLRT_res.iloc[1:]\n",
    "BLRT_res = BLRT_res[[\"n clust\", \"p\"]]\n",
    "BLRT_res.to_csv(\"output/models/BLRT_simplex.csv\", index=False)\n",
    "\n",
    "BLRT_res.style.hide(axis=0).format({\"p\": \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52be3de-aa6c-4a82-b77e-a4fccf6f8f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters for LCA without covariates and sample weights is 7 according to BLRT.\n"
     ]
    }
   ],
   "source": [
    "if BLRT_res[BLRT_res['p'] > 0.05].empty:\n",
    "    best_LCA = None\n",
    "else:\n",
    "    best_LCA = BLRT_res[BLRT_res['p'] > 0.05]\n",
    "    best_LCA = best_LCA.index[0]\n",
    "\n",
    "print(f\"Optimal number of clusters for LCA without covariates and sample weights is {best_LCA} according to BLRT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf745ff-64c4-46fb-8449-65d24d5a3391",
   "metadata": {},
   "source": [
    "### With covariates and sample weights\n",
    "Custom implementation as the wrapper function provided by StepMix does not allow for sample weights. It is much slower and yields opposite results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e39892-495e-42c1-a9b7-f56b4fa6b06a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 500,}\n",
    "\n",
    "latent_mod = StepMix(\n",
    "    measurement = 'categorical_nan',\n",
    "    n_init = 7,\n",
    "    abs_tol = 1e-4,\n",
    "    rel_tol = 1e-4,\n",
    "    init_params = 'random',\n",
    "    structural = 'covariate',\n",
    "    structural_params = opt_params,\n",
    "    progress_bar = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfedfeb0-4352-4a3c-affb-7dec86108e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "BLRT = blrt_sweep_custom(\n",
    "    latent_mod,\n",
    "    data_ni_f,\n",
    "    controls_dum,\n",
    "    sample_weight = weights,\n",
    "    low = 1,\n",
    "    high = 8,\n",
    "    n_repetitions = 500,\n",
    "    n_jobs = max_threads)\n",
    "e_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19211cf0-6738-433e-aa23-c83854020029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {(e_time - s_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b9d50-04c0-4128-bce1-cc2961d94f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BLRT_res = pd.concat([pd.DataFrame({'p': [np.nan]}), BLRT]).reset_index(drop=True) # Add a row for the saturated model\n",
    "BLRT_res[\"n clust\"] = [f\"{i+1} vs. {i} clust\" for i in BLRT_res.index]\n",
    "BLRT_res = BLRT_res.iloc[1:]\n",
    "BLRT_res = BLRT_res[[\"n clust\", \"p\"]]\n",
    "BLRT_res.to_csv(\"output/models/BLRT_complex.csv\", index=False)\n",
    "\n",
    "BLRT_res.style.hide(axis=0).format({\"p\": \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f574a71-b674-4fb5-a395-4b2d2969c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BLRT_res[BLRT_res['p'] > 0.05].empty:\n",
    "    best_LCA = None\n",
    "else:\n",
    "    best_LCA = BLRT_res[BLRT_res['p'] > 0.05]\n",
    "    best_LCA = best_LCA.index[0]\n",
    "\n",
    "print(f\"Optimal number of clusters for LCA with covariates and sample weights is {best_LCA} according to BLRT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7062a2-2baf-4263-9acf-b9bc7f8200a5",
   "metadata": {},
   "source": [
    "# Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63d684-cd9c-43f6-9e4d-f457752063f6",
   "metadata": {},
   "source": [
    "Compare models...\n",
    "- Categorical (= LCA) or continuous (= LPA / GMM)\n",
    "- With missing or imputed values\n",
    "- With or without survey weights\n",
    "- With or without covariates\n",
    "\n",
    "Regarding LPA...\n",
    "- `gaussian_diag_nan` does not converge and `gaussian_diag` tends to overfit. Hence the use of `gaussian_spherical`, which is less flexible. \n",
    "- Convergence becomes problematic for LPA above 13-14 classes, making scaling is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc76e10-4c0b-4829-98d9-1307ca486931",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = ['categorical', 'continuous']\n",
    "missing_values = ['without', 'with']\n",
    "covariates = ['without', 'with']\n",
    "sample_weights = ['without', 'with']\n",
    "\n",
    "max_clust = 16\n",
    "clust_range = range(1, max_clust+1)\n",
    "latent_params = list(product(measurements, missing_values, covariates, sample_weights))\n",
    "latent_grid = product(clust_range, latent_params)\n",
    "\n",
    "def set_data(msrt, NAs):\n",
    "    if msrt == 'categorical' and NAs == 'with':\n",
    "        return data_ni_f\n",
    "    elif msrt == 'categorical' and NAs == 'without':\n",
    "        return data_f\n",
    "    elif msrt == 'continuous' and NAs == 'with':\n",
    "        return data_ni_n\n",
    "    elif msrt == 'continuous' and NAs == 'without':\n",
    "        return data_n\n",
    "\n",
    "def set_measurement(msrt, NAs):\n",
    "    if msrt == 'categorical' and NAs == 'with':\n",
    "        return 'categorical_nan'\n",
    "    elif msrt == 'categorical' and NAs == 'without':\n",
    "        return 'categorical'\n",
    "    elif msrt == 'continuous' and NAs == 'with':\n",
    "        return 'gaussian_spherical_nan'\n",
    "    elif msrt == 'continuous' and NAs == 'without':\n",
    "        return 'gaussian_spherical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a46013-27ca-46c9-bc6a-f9b44aa2f9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs = max_threads)(\n",
    "    delayed(do_StepMix)(\n",
    "        data = set_data(msrt, NAs),\n",
    "        controls = controls_dum if covar == 'with' else None,\n",
    "        n = n_clust,\n",
    "        msrt = set_measurement(msrt, NAs), \n",
    "        covar = covar,\n",
    "        weights = weights if wgt == 'with' else None)\n",
    "    for n_clust, (msrt, NAs, covar, wgt) in tqdm(latent_grid, desc = 'Fitting latent models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d31713-100d-495a-9c09-4f5ce247c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_all = pd.DataFrame(results)\n",
    "\n",
    "LCA = latent_all[latent_all['params'].apply(lambda x: 'categorical' in x.get('msrt', ''))]\n",
    "LPA = latent_all[latent_all['params'].apply(lambda x: 'gaussian' in x.get('msrt', ''))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942c6fa-1dd3-4e0e-9dbf-2c1cc36a50f6",
   "metadata": {},
   "source": [
    "## LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c5a63-2f4c-4693-be65-8723dcab35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(param_dict):\n",
    "    return f\"msrt:{param_dict.get('msrt')}, NAs:{param_dict.get('NAs')}, covar:{param_dict.get('covar')}, wgt:{param_dict.get('wgt')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65257a-5912-49f2-a3fc-ffdd36588711",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1_metrics = ['sabic', 'aic', 'classif_error', 'LL']\n",
    "row2_metrics = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = row1_metrics + row2_metrics\n",
    "\n",
    "LCA.loc[:, 'label'] = LCA['params'].apply(extract_label)\n",
    "\n",
    "# Create a 3-row x 4-column grid\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(22, 18), sharex=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot metrics in first 8 axes\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    for label, group in LCA.groupby('label'):\n",
    "        group = group.sort_values('n_clust')\n",
    "        ax.plot(group['n_clust'], group[metric], marker='', label=label)\n",
    "    ax.set_title(metric.upper())\n",
    "    ax.set_xlabel(\"Number of Clusters\")\n",
    "    ax.set_ylabel(metric.upper())\n",
    "\n",
    "# Hide any unused subplot (in case)\n",
    "for j in range(8, 12):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Legend in the entire third row (axes 8 to 11 merged)\n",
    "# Remove the 4 axes in row 3 and create one big axis there:\n",
    "for ax in axes[8:12]:\n",
    "    fig.delaxes(ax)\n",
    "legend_ax = fig.add_subplot(3,1,3)  # new axis spanning entire bottom row\n",
    "\n",
    "legend_ax.axis('off')  # no axis lines or ticks\n",
    "\n",
    "# Create dummy lines for legend from any group (using first group)\n",
    "first_label = next(iter(LCA['label'].unique()))\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "for label, group in LCA.groupby('label'):\n",
    "    line, = legend_ax.plot([], [], marker='o', label=label)\n",
    "    lines.append(line)\n",
    "    labels.append(label)\n",
    "\n",
    "legend_ax.legend(lines, labels, loc='center', ncol=4, title=\"Combination\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "fig.suptitle(\"Model Fit and Clustering Metrics vs. Number of Clusters\", fontsize=16, y=0.98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647f6e7-0fe0-4d07-b927-45d794a51022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your metric groups\n",
    "metrics_row1 = ['aic', 'classif_error', 'LL', 'sabic']\n",
    "metrics_row2 = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = metrics_row1 + metrics_row2\n",
    "\n",
    "maximize_metrics = {'LL', 'silhouette', 'calinski_harabasz'}\n",
    "marker_styles = ['D', '*']  # diamond = best, star = 2nd best\n",
    "marker_alpha = [0.5, 0.8]\n",
    "marker_size = [90, 80]\n",
    "LCA.loc[:, 'label'] = LCA['params'].apply(extract_label)\n",
    "unique_labels = LCA['label'].unique()\n",
    "colors = {label: plt.cm.tab20(i % 20) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Set up GridSpec with 3 rows: 2 for plots, 1 for legend\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "gs = gridspec.GridSpec(3, 4, height_ratios=[1, 1, 0.1])  # last row is for legend\n",
    "\n",
    "axes = [fig.add_subplot(gs[i // 4, i % 4]) for i in range(8)]\n",
    "\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    maximize = metric in maximize_metrics\n",
    "\n",
    "    df_metric = LCA.dropna(subset=[metric])\n",
    "\n",
    "    sorted_df = (\n",
    "        df_metric\n",
    "        .sort_values(metric, ascending=not maximize)\n",
    "        .groupby(\"n_clust\")\n",
    "        .head(2)\n",
    "        .copy()\n",
    "    )\n",
    "    sorted_df['rank'] = sorted_df.groupby('n_clust').cumcount()\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        marker = marker_styles[row['rank']]\n",
    "        alpha = marker_alpha[row['rank']]\n",
    "        size = marker_size[row['rank']]\n",
    "        ax.scatter(\n",
    "            row['n_clust'], row[metric],\n",
    "            color=colors[row['label']],\n",
    "            marker=marker,\n",
    "            alpha=alpha,\n",
    "            s=size,\n",
    "            label=row['label'] if row['rank'] == 0 else None\n",
    "        )\n",
    "\n",
    "    title = \"Classification error\" if metric == 'classif_error' else metric\n",
    "    ax.set_title(title.upper())\n",
    "    # ax.set_xlabel(\"Number of Clusters\")\n",
    "    # ax.set_ylabel(metric.upper())\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "# Create an extra subplot just for the legend\n",
    "legend_ax = fig.add_subplot(gs[2, :])  # full width on third row\n",
    "legend_ax.axis('off')\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='o', linestyle='None',\n",
    "               color=colors[label], label=label)\n",
    "    for label in unique_labels\n",
    "]\n",
    "legend_ax.legend(handles=legend_handles, loc='center', ncol=4, title=\"Params\", fontsize='medium')\n",
    "\n",
    "plt.suptitle(\"Top 2 Models per Number of Clusters Across Metrics\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c143b4-f7ff-4f99-9d7f-0ab82ae7a444",
   "metadata": {},
   "source": [
    "## LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde0e39-2a90-4715-9a7d-f68fa7413053",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1_metrics = ['sabic', 'aic', 'classif_error', 'LL']\n",
    "row2_metrics = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = row1_metrics + row2_metrics\n",
    "\n",
    "LPA.loc[:, 'label'] = LPA['params'].apply(extract_label)\n",
    "\n",
    "# Create a 3-row x 4-column grid\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(22, 18), sharex=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot metrics in first 8 axes\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    for label, group in LPA.groupby('label'):\n",
    "        group = group.sort_values('n_clust')\n",
    "        ax.plot(group['n_clust'], group[metric], marker='', label=label)\n",
    "    ax.set_title(metric.upper())\n",
    "    ax.set_xlabel(\"Number of Clusters\")\n",
    "    ax.set_ylabel(metric.upper())\n",
    "\n",
    "# Hide any unused subplot (in case)\n",
    "for j in range(8, 12):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Legend in the entire third row (axes 8 to 11 merged)\n",
    "# Remove the 4 axes in row 3 and create one big axis there:\n",
    "for ax in axes[8:12]:\n",
    "    fig.delaxes(ax)\n",
    "legend_ax = fig.add_subplot(3,1,3)  # new axis spanning entire bottom row\n",
    "\n",
    "legend_ax.axis('off')  # no axis lines or ticks\n",
    "\n",
    "# Create dummy lines for legend from any group (using first group)\n",
    "first_label = next(iter(LPA['label'].unique()))\n",
    "lines = []\n",
    "labels = []\n",
    "\n",
    "for label, group in LPA.groupby('label'):\n",
    "    line, = legend_ax.plot([], [], marker='o', label=label)\n",
    "    lines.append(line)\n",
    "    labels.append(label)\n",
    "\n",
    "legend_ax.legend(lines, labels, loc='center', ncol=4, title=\"Combination\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "fig.suptitle(\"Model Fit and Clustering Metrics vs. Number of Clusters\", fontsize=16, y=0.98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f6956-912e-4861-823f-3920acd29fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your metric groups\n",
    "metrics_row1 = ['aic', 'classif_error', 'LL', 'sabic']\n",
    "metrics_row2 = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "all_metrics = metrics_row1 + metrics_row2\n",
    "\n",
    "maximize_metrics = {'LL', 'silhouette', 'calinski_harabasz'}\n",
    "marker_styles = ['D', '*']  # diamond = best, star = 2nd best\n",
    "marker_alpha = [0.5, 0.8]\n",
    "marker_size = [90, 80]\n",
    "LPA.loc[:, 'label'] = LPA['params'].apply(extract_label)\n",
    "unique_labels = LPA['label'].unique()\n",
    "colors = {label: plt.cm.tab20(i % 20) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Set up GridSpec with 3 rows: 2 for plots, 1 for legend\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "gs = gridspec.GridSpec(3, 4, height_ratios=[1, 1, 0.1])  # last row is for legend\n",
    "\n",
    "axes = [fig.add_subplot(gs[i // 4, i % 4]) for i in range(8)]\n",
    "\n",
    "for i, metric in enumerate(all_metrics):\n",
    "    ax = axes[i]\n",
    "    maximize = metric in maximize_metrics\n",
    "\n",
    "    df_metric = LPA.dropna(subset=[metric])\n",
    "\n",
    "    sorted_df = (\n",
    "        df_metric\n",
    "        .sort_values(metric, ascending=not maximize)\n",
    "        .groupby(\"n_clust\")\n",
    "        .head(2)\n",
    "        .copy()\n",
    "    )\n",
    "    sorted_df['rank'] = sorted_df.groupby('n_clust').cumcount()\n",
    "\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        marker = marker_styles[row['rank']]\n",
    "        alpha = marker_alpha[row['rank']]\n",
    "        size = marker_size[row['rank']]\n",
    "        ax.scatter(\n",
    "            row['n_clust'], row[metric],\n",
    "            color=colors[row['label']],\n",
    "            marker=marker,\n",
    "            alpha=alpha,\n",
    "            s=size,\n",
    "            label=row['label'] if row['rank'] == 0 else None\n",
    "        )\n",
    "\n",
    "    title = \"Classification error\" if metric == 'classif_error' else metric\n",
    "    ax.set_title(title.upper())\n",
    "    # ax.set_xlabel(\"Number of Clusters\")\n",
    "    # ax.set_ylabel(metric.upper())\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "# Create an extra subplot just for the legend\n",
    "legend_ax = fig.add_subplot(gs[2, :])  # full width on third row\n",
    "legend_ax.axis('off')\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='o', linestyle='None',\n",
    "               color=colors[label], label=label)\n",
    "    for label in unique_labels\n",
    "]\n",
    "legend_ax.legend(handles=legend_handles, loc='center', ncol=4, title=\"Params\", fontsize='medium')\n",
    "\n",
    "plt.suptitle(\"Top 2 Models per Number of Clusters Across Metrics\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
